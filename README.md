# ðŸ§  AI Agent: Video Transcription & Summarization

This project automatically **extracts audio from a video**, transcribes it using **OpenAI Whisper**, and then **summarizes the transcript** using a Hugging Face transformer model like `facebook/bart-large-cnn`.

---

## ðŸ“ Project Structure

```
AI Agent Transcribing and Summarizing/
â”œâ”€â”€ main.py                 # Orchestrates video-to-summary pipeline
â”œâ”€â”€ transcriber.py          # Handles audio extraction and Whisper transcription
â”œâ”€â”€ summarizer.py           # Uses a transformer model to summarize text
â”œâ”€â”€ utils.py                # Contains chunking logic for large transcripts
â”œâ”€â”€ example_video.mp4       # Sample video file to test the pipeline
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md               # This file
```

---

## ðŸš€ Features

- ðŸŽ¥ Extracts audio from any video
- ðŸ“ Transcribes speech to text using OpenAI Whisper
- âœ‚ï¸ Automatically chunks long transcripts
- ðŸ“„ Summarizes text using Hugging Face transformer models
- âš™ï¸ Supports multiple Whisper sizes (`tiny`, `base`, `small`, `medium`, `large`)

---

## ðŸ”§ Setup

### 1. Clone the repo

```bash
git clone https://github.com/your-username/video-audio-summarizer.git
cd video-audio-summarizer
```

### 2. Create and activate a conda environment

```bash
conda create -n video_audio_summarizer python=3.9
conda activate video_audio_summarizer
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

If you donâ€™t have `requirements.txt`, you can install manually:

```bash
pip install openai-whisper torch transformers ffmpeg-python
```

---

## â–¶ï¸ How to Run

Run the main script with a video file:

```bash
python main.py
```

### You can modify the parameters in `main.py`:

- `model_size`: Whisper model size (`tiny`, `base`, `small`, `medium`, `large`)
- `summarizer_model_name`: Hugging Face summarization model (`facebook/bart-large-cnn`, etc.)
- `use_chunking`: Set `True` to enable chunk-wise summarization for long transcripts

---

## ðŸ’¡ Optional Enhancements (TODO)

- Build a Streamlit UI for uploading videos and viewing summaries
- Add support for more summarizer models
- Handle multi-language audio with Whisper's language detection
- Display video timeline with summary mapping

---

## ðŸ›  Example Requirements

```txt
openai-whisper
torch
transformers
ffmpeg-python
```

Create it using:

```bash
pip freeze > requirements.txt
```

---
